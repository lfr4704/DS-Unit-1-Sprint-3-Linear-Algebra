{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_134_Clustering_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-3rVFtGLMJM"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_VS3FFSFLR3a"
      },
      "source": [
        "# 1) Use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "899RK3bBn4OE"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ws5R9X6hLJQ2",
        "outputId": "4e98c7bb-b2f3-46a7-ddce-72d6aba25b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IHDDqaU-ove4"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "86MHoPJon_aC",
        "outputId": "4b4bda35-5098-48ad-b706-b8cb6e90eff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "df = df.drop('diagnosis', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302        17.99  ...                  0.11890          NaN\n",
              "1    842517        20.57  ...                  0.08902          NaN\n",
              "2  84300903        19.69  ...                  0.08758          NaN\n",
              "3  84348301        11.42  ...                  0.17300          NaN\n",
              "4  84358402        20.29  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toDesdIf0XxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51be81e9-14f7-4afd-d0aa-f163e67bdf24"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09lL4cCek4YY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "aed40517-27f6-4d5f-b30c-68f0d9e66c1c"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           0\n",
              "radius_mean                  0\n",
              "texture_mean                 0\n",
              "perimeter_mean               0\n",
              "area_mean                    0\n",
              "smoothness_mean              0\n",
              "compactness_mean             0\n",
              "concavity_mean               0\n",
              "concave points_mean          0\n",
              "symmetry_mean                0\n",
              "fractal_dimension_mean       0\n",
              "radius_se                    0\n",
              "texture_se                   0\n",
              "perimeter_se                 0\n",
              "area_se                      0\n",
              "smoothness_se                0\n",
              "compactness_se               0\n",
              "concavity_se                 0\n",
              "concave points_se            0\n",
              "symmetry_se                  0\n",
              "fractal_dimension_se         0\n",
              "radius_worst                 0\n",
              "texture_worst                0\n",
              "perimeter_worst              0\n",
              "area_worst                   0\n",
              "smoothness_worst             0\n",
              "compactness_worst            0\n",
              "concavity_worst              0\n",
              "concave points_worst         0\n",
              "symmetry_worst               0\n",
              "fractal_dimension_worst      0\n",
              "Unnamed: 32                569\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ528WlRlIt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "befff995-8414-4798-b1f9-fd4458a5ac47"
      },
      "source": [
        "df = df.drop('Unnamed: 32', axis=1)\n",
        "df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rskC80k3OKMA"
      },
      "source": [
        "## Let's do it!\n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to use the elbow method to decide on the number of clusters to use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTc9WpEjfwGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U92Y3jNKPpjJ",
        "colab": {}
      },
      "source": [
        "# Perform K-Means Clustering on the Dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CilMb3FN_ztI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "609c9f4f-9936-4c1a-b6f2-0ac8a9fc3ce9"
      },
      "source": [
        "#applying the elbow method\n",
        "#https://stackoverflow.com/questions/19197715/scikit-learn-k-means-elbow-criterion\n",
        "\n",
        "#sum of squared erros SSE\n",
        "sse = {}\n",
        "for k in range(1,10):\n",
        "  #print(df)\n",
        "  kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df)\n",
        "  df['clusters'] = kmeans.labels_\n",
        "  #print(df['clusters'])\n",
        "  sse[k] = kmeans.inertia_ #Inertia: Sum of distances of samples to their closest cluster center\n",
        "plt.figure()\n",
        "plt.plot(list(sse.keys()), list(sse.values()))\n",
        "plt.xlabel('Number of cluster')\n",
        "plt.ylabel('SSE')\n",
        "plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAERCAYAAABxZrw0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-AQzIkBlq7r",
        "colab_type": "text"
      },
      "source": [
        "#the elbow is 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ghqYSxrP_FE"
      },
      "source": [
        "## Check you work: \n",
        "\n",
        "This is something that in a truly unsupervised learning situation **WOULD NOT BE POSSIBLE**. But for educational purposes go back and grab the true diagnosis column (label) from the original dataset. Take your cluster labels and compare them to the original diagnosis column. You can make scatterplots for each to see how they compare or you can calculate a percent accuracy score like: \n",
        "\\begin{align}\n",
        "\\frac{\\text{Num Correct Labels}}{\\text{Num Total Observations}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OIG7-yGLP-eA",
        "colab": {}
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BedOTS0eJ9_K"
      },
      "source": [
        "# 2) Perform PCA on your dataset first and *then* use k-means clustering. \n",
        "\n",
        "- You need to standardize your data before PCA.\n",
        "- First try clustering just on PC1 and PC2 so that you can make a scatterplot of your clustering.\n",
        "- Then use use a scree plot to decide how many principal components to include in your clustering, and use however many principal components you need in order to retain 90% of the variation of the original dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dW1AeAK8PNah",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PkrfbzfBROpP"
      },
      "source": [
        "## Check your work: \n",
        "\n",
        "- Compare your PC1, PC2 clustering scatterplot to the clustering scatterplots you made on the raw data\n",
        "- Calculate accuracy scores for both the PC1,PC2 Principal component clustering and the 90% of explained variance clustering.\n",
        "\n",
        "How do your accuracy scores -when preprocessing the data with PCA- compare to the accuracy when simply clustering on the raw data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wKBwVaGOOYsq"
      },
      "source": [
        "# Stretch Goals:\n",
        "\n",
        "- Study for the Sprint Challenge\n",
        "- Work on your Data Storytelling Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9p2djjY5LNWd",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}